services:
  jupyter:
    image: franzdiebold/datascience-ultimate:latest
    ports:
      - 8888:8888
    volumes:
      - ./jupyter:/usr/src/app
    working_dir: /usr/src/app
    models:
      - smollm2
      - gemma3n

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    volumes:
      - ./open_webui:/app/backend/data
    models:
      - smollm2
      - gemma3n
    ports:
      - 8080:8080
    environment:
      - ENV=dev
      - WEBUI_AUTH=False
      - OPENAI_API_BASE_URL=http://model-runner.docker.internal/engines/v1
      - OPENAI_API_KEY=na

  langgraph-server:
    build: ./langgraph_server
    volumes:
      - ./langgraph_server:/app
    ports:
      - 2024:2024
    models:
      - smollm2
      - gemma3n

  agent-inbox:
    image: node:latest
    volumes:
      - ./agent_inbox:/usr/src/app
    working_dir: /usr/src/app
    ports:
      - "3000:3000"
    depends_on:
      - langgraph-server
    entrypoint: ["/bin/bash", "entrypoint.sh"]

  agent-chat-ui:
    image: node:latest
    volumes:
      - ./agent_chat_ui:/usr/src/app
    working_dir: /usr/src/app
    ports:
      - "5173:5173"
    depends_on:
      - langgraph-server
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:2024
      - NEXT_PUBLIC_ASSISTANT_ID=agent
    entrypoint: ["/bin/bash", "entrypoint.sh"]

  mcp-inspector:
    image: ghcr.io/modelcontextprotocol/inspector:latest
    ports:
      - "6274:6274"
      - "6277:6277"
    environment:
      - ALLOWED_ORIGINS=http://0.0.0.0:6274,http://localhost:6274
      - HOST=0.0.0.0
      - DANGEROUSLY_OMIT_AUTH=true

models:
  smollm2:
    model: ai/smollm2
  gemma3n:
    model: ai/gemma3n
